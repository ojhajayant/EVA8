{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Implementation for a neural network that can:\n",
        "\n",
        "\n",
        "1.   take 2 inputs :\n",
        "> an image from the MNIST dataset (say 5), and a random number between 0 and 9, (say 7)\n",
        "\n",
        "\n",
        "2.  and gives two outputs(as in example below) :\n",
        "> for example: the \"number\" that was represented by the MNIST image (predict 5), and the \"sum\" of this number with the random number and the input image to the network (predict 5 + 7 = 12)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-fmXf1ft9GKU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### import satements for all required Python packages."
      ],
      "metadata": {
        "id": "xGMZbnjR89wT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r49mFAZCvZez"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "''''from  __future__ import' statements can be used on *top-of* one's Python \n",
        "2.x code to enable new language features, that are not available in the older \n",
        "versions of Python. Esp. 'from __future__ import print_function' is a \n",
        "statement that one can use at the *top-of* the Python 2.x code to enable the \n",
        "print *function* from Python 3.x. In Python 2.x, the print *statement* is \n",
        "used to print to the standard output stream, whereas in Python 3.x, the print \n",
        "*function* is used. By using from __future__ import print_function, one can \n",
        "use the print *function* in the Python 2.x code, which can make it easier to \n",
        "port the code to Python 3.x in the future. '''\n",
        "import torch\n",
        "\n",
        "'''imports the torch module. This module provides functions for working with \n",
        "PyTorch, a popular open-source machine learning library for Python that is \n",
        "based on the Torch library used primarily for natural language processing and \n",
        "computer vision tasks. PyTorch provides a high-level interface for working \n",
        "with neural networks and allows users to perform complex operations on \n",
        "tensors with strong acceleration on many-core GPUs. '''\n",
        "import torch.nn as nn\n",
        "\n",
        "'''imports the torch.nn module (into the namespace nn by convention) from the \n",
        "torch package. This module provides a set of classes and functions that are \n",
        "commonly used to build and train neural networks in PyTorch. It contains \n",
        "classes for defining various types of layers in a neural network, as well as \n",
        "methods for forward propagation, backward propagation, and optimization. '''\n",
        "import torch.nn.functional as F\n",
        "\n",
        "'''imports torch.nn.functional module into the namespace F by convention. \n",
        "This module contains all the functions in the torch.nn library (whereas other \n",
        "parts of the library contain classes) and a wide range of loss and activation \n",
        "functions, one also finds here, some convenient functions for creating neural \n",
        "nets, such as pooling functions. '''\n",
        "import torch.optim as optim\n",
        "\n",
        "'''imports the torch.optim module from the torch package into the namespace \n",
        "optim. This module provides a set of classes and functions for \n",
        "*optimizing-the-parameters* of a neural network in PyTorch. It contains \n",
        "implementations of various optimization algorithms, such as stochastic \n",
        "gradient descent (SGD), Adam, and RMSprop. By importing the optim module and \n",
        "using the classes and functions it provides, one can *train-a-neural-network* \n",
        "in PyTorch by specifying the optimization algorithm and the network's \n",
        "parameters to optimize. '''\n",
        "\n",
        "'''imports the datasets & transforms  modules from the torchvision package. \n",
        "The torchvision package is a popular library for working with image data in \n",
        "PyTorch. It contains a collection of functions and classes for loading, \n",
        "transforming, and analyzing image data. The *datasets module* provides \n",
        "classes for loading and organizing image data into datasets that can be \n",
        "easily used to train a neural network. The transforms module provides a set \n",
        "of common image transformations that can be applied to images in a dataset. \n",
        "These transformations include operations such as resizing, cropping, \n",
        "and normalizing the images. '''\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from torchsummary import summary\n",
        "'''module is a progress bar library that is used to provide a visual indication\n",
        "of the progress of a long-running operation in a Python script.'''\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Some globals defined here"
      ],
      "metadata": {
        "id": "QUyIIXf4dMBP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s3kmDg87qV5E"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "epochs = 10\n",
        "train_losses_in1 = []\n",
        "train_losses_in2 = []\n",
        "test_losses_in1 = []\n",
        "test_losses_in2 = []\n",
        "train_acc_in1 = []\n",
        "train_acc_in2 = []\n",
        "test_acc_in1 = []\n",
        "test_acc_in2 = []\n",
        "class_names = [\"zero\",  # index 0\n",
        "               \"one\",  # index 1\n",
        "               \"two\",  # index 2\n",
        "               \"three\",  # index 3\n",
        "               \"four\",  # index 4\n",
        "               \"five\",  # index 5\n",
        "               \"six\",  # index 6\n",
        "               \"seven\",  # index 7\n",
        "               \"eight\",  # index 8\n",
        "               \"nine\"]  # index 9"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom dataset-class required here:\n",
        "The constructor takes in following params:\n",
        ">train_data (dict): \n",
        "A dictionary having two columns(/keys):-1. \"mnist_input\" {ndarry: (60000,28,28)} (representing the numpy-format MNIST training data, and named as \"train_mnist_set_array\", this is kept in numpy format, so as to be able to use the \"transform\" callable, provided as argument (\"transform_in1\") for this custom-dataset class, so as to convert to the required Tensor format, with all required posible list of transforms applied to it.\n",
        " &  2. \"rand_num_input\"{Tensor:(60000,10)} (representing the Random-number input from the [0,9] in one-hot-encoded form, named as \"train_rand_num_set_array_one_hot\", this does not require any transform, hence though there is a 2nd transform-interface provided for the 2nd input of this overall neural network (provided as argument \"transform_in2\"), butinterface not used.\n",
        "\n",
        "> test_data (dict): A dictionary having two columns(/keys):-1. \"mnist_input\" {ndarry: (10000,28,28)} (representing the numpy-format MNIST test data, and named as \"test_mnist_set_array\", this is kept in numpy format, so as to be able to use the \"transform\" callable, provided as argument (\"transform_in1\") for this custom-dataset class, so as to convert to the required Tensor format, with all required posible list of transforms applied to it.\n",
        " &  2. \"rand_num_input\"{Tensor:(60000,10)} (representing the Random-number input from the [0,9] in one-hot-encoded form, named as \"test_rand_num_set_array_one_hot\", this does not require any transform, hence though, there is a 2nd transform-interface provided for the 2nd input of this overall neural network (provided as argument \"transform_in2\"), but interface not used.\n",
        "\n",
        ">train_target (dict): A dictionary having two columns(/keys):-1. \"mnist_output\"{Tensor: (60000,)} (representing the Tensor-format MNIST train-labels/targets, and named as \"train_mnist_set_array_targets\".\n",
        " &  2. \"sum_of_mnist_rand_num_output\"{Tensor:(60000,19)} (representing the sum output expected to be from the [0,18] in one-hot-encoded form, named as \"train_sum_of_mnist_rand_num_set_array_one_hot\".\n",
        "\n",
        ">test_target (dict): A dictionary having two columns(/keys):-1. \"mnist_output\"{Tensor: (10000,)} (representing the Tensor-format MNIST test-labels/targets, and named as \"test_mnist_set_array_targets\".\n",
        " &  2. \"sum_of_mnist_rand_num_output\"{Tensor:(60000,19)} (representing the sum output expected to be from the [0,18] in one-hot-encoded form, named as \"test_sum_of_mnist_rand_num_set_array_one_hot\".\n",
        "\n",
        ">train: True if the dataset will be used in train mode(by default kept True)\n",
        "\n",
        ">test: True if the dataset will be used in test mode(by default kept False).Assert if both train & test flag true simultaneously.)\n",
        "\n",
        ">transform_in1: a \"callable\" data-transform inteface provided for the part# 1 of the neural network (made up of the CNN layers & catering to the mnist image input) By default kept as None.\n",
        "\n",
        ">transform_in2: a \"callable\" data-transform inteface provided for the part# 2 of the neural network (made up of the FC-layers & catering to the random number input) By default kept as None.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            "
      ],
      "metadata": {
        "id": "1H3WSqmuAa8J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ITeT1FOsqYEH"
      },
      "outputs": [],
      "source": [
        "class MNIST_RAND_IN_Dataset(Dataset):\n",
        "    \"\"\"Dataset For MNIST train/test & Rand-Num-In & Summation target \"\"\"\n",
        "\n",
        "    def __init__(self, train_data, test_data, train_target, test_target,\n",
        "                 train=True, test=False, transform_in1=None,\n",
        "                 transform_in2=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            train_data (dict): contains tensor-format train-data for both:\n",
        "            \"mnist_input\"{Tensor: (60000,28,28)} & \"rand_num_input\"{Tensor:\n",
        "            (60000,10)}\n",
        "            test_data (dict): contains tensor-format test-data for both:\n",
        "            \"mnist_input\"{Tensor: (10000,28,28)} & \"rand_num_input\"{Tensor:\n",
        "            (10000,10)}\n",
        "            train_target (dict): contains tensor-format train-targets for both:\n",
        "            \"mnist_output\"{Tensor: (60000,10)} & \"sum_of_mnist_rand_num_output\"\n",
        "            {Tensor: (60000,19)}\n",
        "            test_target (dict): contains tensor-format test-targets for both:\n",
        "            \"mnist_output\"{Tensor: (10000,10)} & \"sum_of_mnist_rand_num_output\"\n",
        "            {Tensor: (10000,19)}\n",
        "            train: True if the dataset will be used in train mode\n",
        "            test: True if the dataset will be used in test mode (assert if both\n",
        "                  train & test flag true simultaneously.\n",
        "            transform_in1: a \"callable\" data-transform inteface for mnist image\n",
        "            transform_in2: a \"callable\" data-transform inteface for rand-num in\n",
        "        \"\"\"\n",
        "        #Below class-variables receive the data from\n",
        "        #various dict described above (and implmented under \n",
        "        #a function named: \"source_data()\")\n",
        "\n",
        "        #the numpy-format MNIST training data\n",
        "        self.x_train_mnist = train_data[\"mnist_input\"]\n",
        "        #the Random-number input from the [0,9] in \n",
        "        #one-hot-encoded form\n",
        "        self.x_train_rand_num = train_data[\"rand_num_input\"]\n",
        "        #the numpy-format MNIST test data\n",
        "        self.x_test_mnist = test_data[\"mnist_input\"]\n",
        "        #the Random-number input from the [0,9] in \n",
        "        #one-hot-encoded form\n",
        "        self.x_test_rand_num = test_data[\"rand_num_input\"]\n",
        "        #the Tensor-format MNIST train-labels/targets\n",
        "        self.y_train_mnist = train_target[\"mnist_output\"]\n",
        "        #the sum output expected to be from the [0,18] \n",
        "        #in one-hot-encoded form\n",
        "        self.y_train_sum_of_mnist_rand_num = \\\n",
        "            train_target[\"sum_of_mnist_rand_num_output\"]\n",
        "        #the Tensor-format MNIST train-labels/targets\n",
        "        self.y_test_mnist = test_target[\"mnist_output\"]\n",
        "        #the sum output expected to be from the [0,18] \n",
        "        #in one-hot-encoded form\n",
        "        self.y_test_sum_of_mnist_rand_num = \\\n",
        "            test_target[\"sum_of_mnist_rand_num_output\"]\n",
        "        #train cfg-flag\n",
        "        self.train = train\n",
        "        #test cfg-flag\n",
        "        self.test = test\n",
        "        #assert if the user tried creating test & train\n",
        "        #dataset with both train & test flags same at \n",
        "        #the same time.\n",
        "        assert self.train != self.test\n",
        "        #Transform interface for Input1(mnist image)\n",
        "        #of the NN (being used for ToTensor & Normalize)\n",
        "        self.transform_in1 = transform_in1\n",
        "        #Transform interface for Input2(mrand-num)\n",
        "        #of the NN (not used curently)\n",
        "        self.transform_in2 = transform_in2\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.train:\n",
        "            assert len(self.x_train_mnist) == len(self.x_train_rand_num)\n",
        "            return len(self.x_train_mnist)\n",
        "        else:\n",
        "            assert len(self.x_test_mnist) == len(self.x_test_rand_num)\n",
        "            return len(self.x_test_mnist)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        if self.train:\n",
        "            #create an input tuple for 2 inputs\n",
        "            (mnist_image, rand_num_in) = (self.x_train_mnist[idx],\n",
        "                                          self.x_train_rand_num[idx])\n",
        "            #create an target tuple for 2 outputs\n",
        "            (mnist_target, sum_of_mnist_rand_num_target) = \\\n",
        "                (self.y_train_mnist[idx],\n",
        "                 self.y_train_sum_of_mnist_rand_num[idx])\n",
        "            # print(\"Before transform, values:\")\n",
        "            # plt.imshow(mnist_image)\n",
        "            # plt.show()\n",
        "        else:\n",
        "            (mnist_image, rand_num_in) = (self.x_test_mnist[idx],\n",
        "                                          self.x_test_rand_num[idx])\n",
        "            (mnist_target, sum_of_mnist_rand_num_target) = \\\n",
        "                (self.y_test_mnist[idx], self.y_test_sum_of_mnist_rand_num[idx])\n",
        "        if self.transform_in1:\n",
        "            # if torch.is_tensor(mnist_image):\n",
        "            #     mnist_image = mnist_image.numpy()\n",
        "            mnist_image = self.transform_in1(mnist_image)\n",
        "            # print(\"self.transform_in1: \", self.transform_in1)\n",
        "            # print(\"After transform, values:\")\n",
        "            # plt.imshow(mnist_image.numpy().squeeze())\n",
        "            # plt.show()\n",
        "        if self.transform_in2:\n",
        "            # if torch.is_tensor(mnist_image):\n",
        "            #     mnist_image = mnist_image.numpy()\n",
        "            rand_num_in = self.transform_in2(rand_num_in)\n",
        "\n",
        "        return (mnist_image, rand_num_in), (mnist_target,\n",
        "                                            sum_of_mnist_rand_num_target)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Helper function to provide one-hot-encoded tensor of given width from an input tensor(this one is used by another function, named \"source_data\" which in turn is used to create various required dicts for the custom-dataset class)\n",
        "The method takes in 2 args & returns one as follows:\n",
        ">input_tensor : an input tensor to be encoded\n",
        "\n",
        ">width : width of the one-hot-encoded result.\n",
        "\n",
        ">one_hot: one-hot-encoded tensor output"
      ],
      "metadata": {
        "id": "ak-q6LYkWoef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_custom(input_tensor, width):\n",
        "    # Convert the data type of the input tensor to long\n",
        "    input_tensor = input_tensor.long()\n",
        "    # Create an identity matrix with the desired one-hot encoded width\n",
        "    one_hot_tensor = torch.eye(width, dtype=torch.float)\n",
        "\n",
        "    # Use the input tensor as an index tensor to index into the one-hot tensor\n",
        "    one_hot = one_hot_tensor[input_tensor]\n",
        "    return one_hot"
      ],
      "metadata": {
        "id": "V2BoZ98lWnPl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to provide various data/target dicts and feed into the  custom-dataset class descibed earlier:\n",
        "The method takes in no args but returns following:\n",
        ">train_data (dict): same as described in earlier comments under class-dataset description\n",
        "\n",
        ">test_data (dict): same as described in earlier comments under class-dataset description\n",
        "\n",
        ">train_target: same as described in earlier comments under class-dataset description\n",
        "\n",
        ">test_target: same as described in earlier comments under class-dataset description"
      ],
      "metadata": {
        "id": "lZ7R9ksjT5WP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def source_data():\n",
        "    # 1. convert the Torchvision MNIST train and test datasets into NumPy\n",
        "    # arrays & take some already tensor format data it provides:\n",
        "    train_mnist_set = datasets.MNIST('./data', train=True, download=True)\n",
        "    test_mnist_set = datasets.MNIST('./data', train=False, download=True)\n",
        "    train_mnist_set_array = train_mnist_set.data.numpy()  # Later transforms\n",
        "    # require them to be numpy array\n",
        "    train_mnist_set_array_targets = train_mnist_set.targets  # a Tensor format\n",
        "    # already.\n",
        "    test_mnist_set_array = test_mnist_set.data.numpy()  # Later transforms\n",
        "    # require them to be numpy array\n",
        "    test_mnist_set_array_targets = test_mnist_set.targets  # a Tensor format\n",
        "    # already.\n",
        "    mnist_train_set_length = len(train_mnist_set)\n",
        "    mnist_test_set_length = len(test_mnist_set)\n",
        "\n",
        "    # 2.  Create a tensor of mnist_train_set_length (60000) random\n",
        "    # numbers from [0-9] in a shape (60000,) & mnist_test_set_length (10000)\n",
        "    # random numbers from [0-9] in a shape (10000,)\n",
        "\n",
        "    # First set the random seed for reproducibility\n",
        "    np.random.seed(0)\n",
        "    # Generate mnist_train_set_length (60000) number of, random integers\n",
        "    # between 0 and 9.Following creates tensor with 60000 elements\n",
        "    # filled with random integers from the range [0, 10).The upper\n",
        "    # bound is not included, so the generated integers will range from 0 to 9\n",
        "    train_rand_num_set_array = torch.randint(low=0, high=10,\n",
        "                                             size=(mnist_train_set_length,),\n",
        "                                             dtype=torch.int)\n",
        "    # similar for test here:\n",
        "    test_rand_num_set_array = torch.randint(low=0, high=10,\n",
        "                                            size=(mnist_test_set_length,),\n",
        "                                            dtype=torch.int)\n",
        "\n",
        "    # 3.    Given two tensors (train_mnist_set_array_targets &\n",
        "    # train_rand_num_set_array) of shape(60000,) with random numbers,\n",
        "    # following creates a tensor with same shape i.e.( 60000,)the sum of\n",
        "    # the elements.The resulting array will have the same shape as the input\n",
        "    # arrays, and will contain the sums of the corresponding elements.\n",
        "    train_sum_of_mnist_rand_num_set_array = \\\n",
        "        torch.add(train_mnist_set_array_targets,\n",
        "                  train_rand_num_set_array)\n",
        "\n",
        "    # Following will generate two tensors with of shape(10000,)\n",
        "    #and calculate the sum of the elements from the same rows of the\n",
        "    # arrays. The resulting tensor will have the same shape as the input\n",
        "    # arrays, and will contain the sums of the corresponding elements.\n",
        "    test_sum_of_mnist_rand_num_set_array = \\\n",
        "        torch.add(test_mnist_set_array_targets,\n",
        "                  test_rand_num_set_array)\n",
        "\n",
        "    # 4.Now encode train & test tensors for inputs & targets for rand_in\n",
        "    # and Sum_out  only.\n",
        "    train_rand_num_set_array_one_hot = one_hot_custom(train_rand_num_set_array,\n",
        "                                                      width=10)\n",
        "    test_rand_num_set_array_one_hot = one_hot_custom(test_rand_num_set_array,\n",
        "                                                     width=10)\n",
        "    train_sum_of_mnist_rand_num_set_array_one_hot = \\\n",
        "        one_hot_custom(train_sum_of_mnist_rand_num_set_array,\n",
        "                       width=19)\n",
        "    test_sum_of_mnist_rand_num_set_array_one_hot = \\\n",
        "        one_hot_custom(test_sum_of_mnist_rand_num_set_array,\n",
        "                       width=19)\n",
        "\n",
        "    train_data = {\n",
        "        # The provision to transform the  \"mnist_input\" part below, into the\n",
        "        # required [0,1) distribution Tensor has already been made under the\n",
        "        # custom Dataset class (with a class constructor-argument named:\n",
        "        # \"transform_in1\", where *_in1 represents the transformation required\n",
        "        # for the input to the part # 1 of this neural network.Similar other\n",
        "        # class constructor-argument named: \"transform_in2\" has also been\n",
        "        # provided to potentially cater to the input to the part #2 of this\n",
        "        # neural network.But currently kept as None.\n",
        "        \"mnist_input\": train_mnist_set_array,\n",
        "        # Below part of the data input: \"rand_num_input\" don't undergo\n",
        "        # transformation through the custom-Dataset inbuilt transform.\n",
        "        #Its already kept in form of a one-hot-encoded tensor.\n",
        "        \"rand_num_input\": train_rand_num_set_array_one_hot\n",
        "    }\n",
        "    train_target = {\n",
        "        # the Tensor-format MNIST train-labels/targets\n",
        "        \"mnist_output\": train_mnist_set_array_targets,\n",
        "        \n",
        "        # the sum output expected to be from the [0,18] in \n",
        "        #one-hot-encoded form\n",
        "        \"sum_of_mnist_rand_num_output\":\n",
        "            train_sum_of_mnist_rand_num_set_array_one_hot\n",
        "    }\n",
        "\n",
        "    test_data = {\n",
        "        # The provision to transform the  \"mnist_input\" part below, into the\n",
        "        # required [0,1) distribution Tensor has already been made under the\n",
        "        # custom Dataset class (with a class constructor-argument named:\n",
        "        # \"transform_in1\", where *_in1 represents the transformation required\n",
        "        # for the input to the part # 1 of this neural network.Similar other\n",
        "        # class constructor-argument named: \"transform_in2\" has also been\n",
        "        # provided to potentially cater to the input to the part #2 of this\n",
        "        # neural network.But currently kept as None.\n",
        "        \"mnist_input\": test_mnist_set_array,\n",
        "        # Below part of the data input: \"rand_num_input\" don't undergo\n",
        "        # transformation through the custom-Dataset inbuilt transform.\n",
        "        #Its already kept in form of a one-hot-encoded tensor.\n",
        "        \"rand_num_input\": test_rand_num_set_array_one_hot\n",
        "    }\n",
        "\n",
        "    test_target = {\n",
        "        # the Tensor-format MNIST train-labels/targets\n",
        "        \"mnist_output\": test_mnist_set_array_targets,\n",
        "        # the sum output expected to be from the [0,18] in \n",
        "        #one-hot-encoded form\n",
        "        \"sum_of_mnist_rand_num_output\":\n",
        "            test_sum_of_mnist_rand_num_set_array_one_hot\n",
        "    }\n",
        "    return train_data, test_data, train_target, test_target"
      ],
      "metadata": {
        "id": "ZwFbIpA8Tvlk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####helper function, to display some of the mnist image data along with rand-in, & sum out, obtained from the above dataset (using dataloader given much below in this code-page.)\n",
        "The method takes in 2 args & returns nothing as follows:\n",
        ">data_ldr : an input dataloader (a usage much below in this page)\n",
        "\n",
        ">num_times : display the sample how many times(default 5)\n",
        "\n"
      ],
      "metadata": {
        "id": "hIM2oBhuddij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_few_batch_samples(data_ldr, num_times=5):\n",
        "    for i in range(num_times):\n",
        "        dataiter = next(iter(data_ldr))\n",
        "        (mnist_image, rand_num_in), (mnist_target,\n",
        "                                     sum_of_mnist_rand_num_target) = dataiter\n",
        "\n",
        "        print(\"mnist_image.shape: \", mnist_image.shape)\n",
        "        print(\"rand_num_in.shape: \", rand_num_in.shape)\n",
        "        print(\"mnist_target.shape: \", mnist_target.shape)\n",
        "        print(\"sum_of_mnist_rand_num_target.shape: \",\n",
        "              sum_of_mnist_rand_num_target.shape)\n",
        "        img_number = np.random.randint(mnist_image.shape[0])\n",
        "        print(\"rand_num_in[{}]=  {}\".format(img_number,\n",
        "                                            rand_num_in[img_number].argmax()))\n",
        "        print(\"mnist_target[{}]=  {}\".format(img_number,\n",
        "                                             mnist_target[img_number].argmax()))\n",
        "        print(\"sum_of_mnist_rand_num_target[{}]=  {}\".format(\n",
        "            img_number,\n",
        "            sum_of_mnist_rand_num_target[img_number].argmax()))\n",
        "        plt.figure().suptitle('{} '.format(\n",
        "            class_names[mnist_target[img_number].argmax()]),\n",
        "            fontsize=20)\n",
        "        _ = plt.imshow(mnist_image.squeeze().numpy()[img_number, ::],\n",
        "                       interpolation='nearest')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "dlvOKQ_qTlyn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####For the neural network(NN), the mnsit image goes thru the given layering below, which, with an input image size of 28x28x1.This forms the first \"part\" of the NN.Actually here, this layering is leveraged off the earlier session assignment, but now merged to cater to the  additional rand-num input and sum_of_mnist_rand_rum output too.The additional set of inputs and outputs are taken thru a layering of fully connected layers.\n",
        "\n",
        ">Please note that for the FC-part a provision is made to potentially go for 2 inputs as well (though currently only one input rand_num goes thru), In case in future experiment an additional input is required that can also be concatenated along (in all one-hot-enoded formats)\n",
        "\n",
        "The Net class construct hence provides these args:\n",
        ">num_inputs_for_fc_part=1 (provision for concatenated 2 outputs, currently only one)\n",
        "\n",
        ">sum_out_features=19 (width 19 one hot encoded sum_out related FC has these out features)\n",
        "\n",
        ">num_hidden_fc_features=100 (a hidden in between FC layer requires these, by default 100)\n"
      ],
      "metadata": {
        "id": "Y8aNGO_2gLp4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input Channels/Image  |  Conv2d/Transform      | Output Channels | RF\n",
        "---------------------|--------------|----------------------|------\n",
        "**28x28x1**              | **(3x3x1)x32**   |      **28x28x32**(padding=1) |      **3x3**\n",
        "             |          `ReLU`  | \n",
        "**28x28x32**             | **(3x3x32)x64**  |      **28x28x64**(padding=1) |      **5x5**  \n",
        "             |          `ReLU`  | \n",
        "**28x28x64**             | *MP(2x2)*  |      **14x14x64** |      **10x10**  \n",
        "**14x14x64**             | **(3x3x64)x128** | **14x14x128**(padding=1)  |  **12x12**\n",
        "             |          `ReLU`  | \n",
        "**14x14x128**            | **(3x3x128)x256**| **14x14x256** (padding=1)|   **14x14** \n",
        "             |          `ReLU`  |\n",
        "**14x14x256**            | *MP(2x2)*  |      **7x7x256** |      **28x28**\n",
        "**7x7x256**              | **(3x3x256)x512**  |**5x5x512** (no padding)|      **30x30**\n",
        "             |          `ReLU`  |   \n",
        "**5x5x512**              | **(3x3x512)x1024**  | **3x3x1024** (no padding)  |  **32x32** \n",
        "             |          `ReLU`  | \n",
        "**3x3x1024**             | **(3x3x1024)x10**  | **1x1x10** (no padding)  |  **34x34**"
      ],
      "metadata": {
        "id": "xsgNsf-Cf78H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SK2vjKwyd7tu"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    \"\"\"\n",
        "    defines a new class called Net, that inherits from the nn.Module class.\n",
        "    This class is used to define a *custom neural network* in PyTorch. With\n",
        "    the  creation a new Net class, one can define the structure of the\n",
        "    network by adding layers and defining the forward propagation method.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_inputs_for_fc_part=1, sum_out_features=19,\n",
        "                 num_hidden_fc_features=100):\n",
        "        super(Net, self).__init__()\n",
        "        # Logical-grouping of the \"Part 1\" of Neural Network, which (in parallel\n",
        "        # with an independent 2nd part of Neural Network), handles the MNIST\n",
        "        # Image label and predicts an MNIST Label out).This part is\n",
        "        # \"structurally\" (i.e. storable parameters/weights wise) composed of\n",
        "        # convolutional layers (with required functional associations to various\n",
        "        # \"functional\"  max-pool, activation etc. layers provided under upcoming\n",
        "        # \"forward propagation\" method named as \"forward\".\n",
        "        # input:28x28x1, kernel_size=3x3,  output:28x28x32, RF:3x3\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32,\n",
        "                               kernel_size=(3, 3), padding=1, bias=False)\n",
        "        # input:28x28x32, kernel_size=3x3, output:28x28x64, RF:5x5\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64,\n",
        "                               kernel_size=(3, 3), padding=1, bias=False)\n",
        "        # MaxPool2d(2, 2):  # input:28x28x64, output:14x14x64, RF:10x10\n",
        "        # input:14x14x64,  kernel_size=3x3,  output:14x14x128, RF:12x12\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128,\n",
        "                               kernel_size=(3, 3), padding=1, bias=False)\n",
        "        # input:14x14x128, kernel_size=3x3,  output:14x14x256, RF:14x14\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256,\n",
        "                               kernel_size=(3, 3), padding=1, bias=False)\n",
        "        # MaxPool2d(2, 2)  # input:14x14x256, output:7x7x256, RF:28x28\n",
        "        # input:7x7x256, kernel_size=3x3,  output:5x5x512(no padding), RF:30x30\n",
        "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=512,\n",
        "                               kernel_size=(3, 3), bias=False)\n",
        "        # input:5x5x512, kernel_size=3x3, output:3x3x1024 (no padding), RF:32x32\n",
        "        self.conv6 = nn.Conv2d(in_channels=512, out_channels=1024,\n",
        "                               kernel_size=(3, 3), bias=False)\n",
        "        # input:3x3x1024,  kernel_size=3x3, output:1x1x10(no padding), RF:34x34\n",
        "        self.mnist_out_conv = nn.Conv2d(in_channels=1024, out_channels=10,\n",
        "                                        kernel_size=(3, 3), bias=False)\n",
        "\n",
        "        # Logical-grouping of the \"Part 2\" of Neural Network, which (in\n",
        "        # parallel with an \"independent\" (with implementation as shown in the\n",
        "        # forward method below) 1st part of Neural Network, handles\n",
        "        # the Random Number input (and also optionally with the current MNIST\n",
        "        # label as a separate future experiment) and predicts Sum of this \n",
        "        # random-num with the MNIST label out).This part is \"structurally\"\n",
        "        # (i.e. storable parameters/weights wise) being composed of \n",
        "        # fully-connected layers here (with other required functional \n",
        "        # associations etc provided under (the same as earlier) upcoming \n",
        "        # \"forward propagation\" method named \"forward\".\n",
        "        self.num_inputs_for_fc_part = num_inputs_for_fc_part  # 1 or 2\n",
        "        self.num_hidden_fc_features = num_hidden_fc_features  # 100\n",
        "        self.sum_out_features = sum_out_features  # 19\n",
        "        # in_features=20 is [10 from MNIST-label, 10 from rand_num in]\n",
        "        assert self.num_inputs_for_fc_part in (1, 2), \\\n",
        "            \"num_inputs_for_fc_part must be 1 or 2\"\n",
        "        self.fc1 = nn.Linear(in_features=10 * self.num_inputs_for_fc_part,\n",
        "                             out_features=self.num_hidden_fc_features,\n",
        "                             bias=False)  #\n",
        "        # self.num_hidden_fc_features (default value 100 here) is the\n",
        "        # capacity boost (an intermediate hidden-layer expansion) to this 2nd\n",
        "        # part of this Neural network, which is made up of all fully connected\n",
        "        # layers and which caters to the random num input (with/without the\n",
        "        # current MNIST label) and generates a 19 wide one-hot-encoded\n",
        "        # sum-output\n",
        "        self.fc2 = nn.Linear(in_features=self.num_hidden_fc_features,\n",
        "                             out_features=self.num_hidden_fc_features,\n",
        "                             bias=False)\n",
        "        self.sum_out_fc = nn.Linear(in_features=self.num_hidden_fc_features,\n",
        "                                    out_features=self.sum_out_features,\n",
        "                                    bias=False)\n",
        "\n",
        "    def forward(self, t1, t2, t3=None):  #\n",
        "        # t3 or mnist_label_in (for a future experiment, is by default None.\n",
        "        #(and by default we cater to just 2 inputs: 1. t1: mnist-image and \n",
        "        # 2.t2:rand-number (10-wide one-hot-encoded number)) But as our \n",
        "        # expectation with such 2 \"random\" inputs with no correlation (along \n",
        "        # with an equally un-correlated Output sum-label) is that they won't \n",
        "        # let this neural network learn(for the 2nd part), hence as a future\n",
        "        # experiment a provision is made to input a 3rd input: t3 too, in form \n",
        "        # of: \"current-mnist-label\" too.With this experiment of using an\n",
        "        # additional mnist-label input along with the random number input is\n",
        "        # that there are chances for neural network to learn now?? (with \n",
        "        # pre-stored randon num input values, for each mnist data along with\n",
        "        # the calculated pre-stored sum of mnist labels and random numbers)\n",
        "\n",
        "        ##### START OF--Functional-grouping of the \"Part 1\" of Neural Network\n",
        "        # Input Layer for Part #1\n",
        "        mnist_image_conv = t1\n",
        "\n",
        "        # 1st Conv2d layer for Part #1:\n",
        "        mnist_image_conv = self.conv1(mnist_image_conv)\n",
        "        mnist_image_conv = F.relu(mnist_image_conv)\n",
        "\n",
        "        # 2nd Conv2d layer for Part #1::\n",
        "        mnist_image_conv = self.conv2(mnist_image_conv)\n",
        "        mnist_image_conv = F.relu(mnist_image_conv)\n",
        "        mnist_image_conv = F.max_pool2d(mnist_image_conv, kernel_size=(2, 2),\n",
        "                                        stride=2)\n",
        "\n",
        "        # 3rd Conv2d layer for Part #1::\n",
        "        mnist_image_conv = self.conv3(mnist_image_conv)\n",
        "        mnist_image_conv = F.relu(mnist_image_conv)\n",
        "\n",
        "        # 4th Conv2d layer for Part #1::\n",
        "        mnist_image_conv = self.conv4(mnist_image_conv)\n",
        "        mnist_image_conv = F.relu(mnist_image_conv)\n",
        "        mnist_image_conv = F.max_pool2d(mnist_image_conv, kernel_size=(2, 2),\n",
        "                                        stride=2)\n",
        "\n",
        "        # 5th Conv2d layer for Part #1::\n",
        "        mnist_image_conv = self.conv5(mnist_image_conv)\n",
        "        mnist_image_conv = F.relu(mnist_image_conv)\n",
        "\n",
        "        # 6th Conv2d layer for Part #1::\n",
        "        mnist_image_conv = self.conv6(mnist_image_conv)\n",
        "        mnist_image_conv = F.relu(mnist_image_conv)\n",
        "\n",
        "        # Final Conv-layer for part1 SHOULD be WITHOUT ReLU!\n",
        "        mnist_image_conv = self.mnist_out_conv(\n",
        "            mnist_image_conv)  # Final conv2d layer for part 1\n",
        "        mnist_image_conv = mnist_image_conv.view(-1, 10)\n",
        "        #Below log_softmax is being removed as F.cross_entropy will be used \n",
        "        #for the two independent set of inputs, and cross-entropy combines\n",
        "        #softmax+nll-loss together.\n",
        "        # mnist_image = F.log_softmax(mnist_image, dim=1)\n",
        "        #####  END OF--Functional-grouping of the \"Part 1\" of Neural Network\n",
        "\n",
        "        #####  START OF--Functional-grouping of the \"Part 2\" of Neural Network\n",
        "        # First we decide here to send either the single one-hot-encoded randum\n",
        "        # num input, or the concat of the one-hot-encoded randum num input with\n",
        "        # current one-hot-encoded mnist label\n",
        "        if t3 is not None:  # i.e. If we want to experiment with a 3rd\n",
        "            # input t3 (representing the current MNIST-label: mnist_label)\n",
        "            # Concatenate t2 (representing rand_num input) and t3 (representing\n",
        "            # mnist_label input) along the second dimension & get that as the\n",
        "            # input to the part #2 of this neural-network.\n",
        "            t_nn_part2_fc = torch.cat((t2, t3), dim=1)\n",
        "        else:\n",
        "            # If mnist_label input is not provided, just get rand_num input\n",
        "            # as the input to the part #2 of this neural-network.\n",
        "            t_nn_part2_fc = t2\n",
        "\n",
        "            # Input Layer for Part #2\n",
        "        sum_output_fc = t_nn_part2_fc\n",
        "        sum_output_fc = sum_output_fc.reshape(-1,\n",
        "                                              self.num_inputs_for_fc_part * 10)\n",
        "\n",
        "        # 1st fully-connected layer fc1 for Part #2:\n",
        "        sum_output_fc = self.fc1(sum_output_fc)\n",
        "        sum_output_fc = F.relu(sum_output_fc)\n",
        "        sum_output_fc = self.fc2(sum_output_fc)\n",
        "        sum_output_fc = F.relu(sum_output_fc)\n",
        "\n",
        "        # 2nd fully-connected layer self.sum_out (last of this Part2 of this\n",
        "        # NN--no ReLU)\n",
        "        sum_output_fc = self.sum_out_fc(sum_output_fc)\n",
        "        #Below log_softmax is being removed as F.cross_entropy will be used \n",
        "        #for the two independent set of inputs, and cross-entropy combines\n",
        "        # sum_output = F.log_softmax(sum_output, dim=1)\n",
        "\n",
        "        #####  END OF--Functional-grouping of the \"Part 2\" of Neural Network\n",
        "\n",
        "        return mnist_image_conv, sum_output_fc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IMVYXQO6eaG9"
      },
      "outputs": [],
      "source": [
        "def get_correct_pred_count(preds, labels):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        preds (Tensor-2D): contains a 2-rank tensor of predictions\n",
        "        labels (Tensor-2D): contains a 2-rank tensor of ground-truth labels\n",
        "    \"\"\"\n",
        "    return preds.argmax(dim=1).eq(labels.argmax(dim=1)).sum().item()\n",
        "\n",
        "\n",
        "def train_model(model, device, train_loader, optimizer_in1, optimizer_in2):\n",
        "    \"\"\"\n",
        "    A train function for a neural network is a function that is used to train\n",
        "    the network on a dataset. The function typically performs the following\n",
        "    steps:\n",
        "    1. Iterate over the training dataset in mini-batches using a loop.\n",
        "    2. For each mini-batch, pass the data through the network to make\n",
        "    predictions.\n",
        "    3. Calculate the loss (error) of the predictions using a loss\n",
        "    function.\n",
        "    4. Use the optimizer to update the network's weights and biases\n",
        "    based on the loss.\n",
        "    5. Repeat the above steps for a specified number of epochs (iterations over\n",
        "    the entire dataset).\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    '''model.train() sets the model to train mode. This is typically done \n",
        "    because some models have different behaviors in training and evaluation \n",
        "    modes. For example, the model may use dropout regularization when in \n",
        "    training mode but not in evaluation mode. '''\n",
        "    pbar = tqdm(train_loader)\n",
        "    correct_in1 = 0\n",
        "    correct_in2 = 0\n",
        "    processed_in1 = 0\n",
        "    processed_in2 = 0\n",
        "    '''above creates a progress bar using the tqdm library. The progress bar \n",
        "    will be used to show the progress of the training loop. '''\n",
        "    for batch_idx, (batch_in1, batch_in2) in enumerate(pbar):\n",
        "        '''starts a for loop that will iterate over the training dataset in \n",
        "        mini-batches. The enumerate function is used to add a counter to the \n",
        "        loop so that the current mini-batch index can be tracked. The \n",
        "        progress bar pbar is passed as the argument to the enumerate function \n",
        "        so that it can be updated on each iteration of the loop. '''\n",
        "        (mnist_image_batch, rand_num_in_batch) = batch_in1\n",
        "        (mnist_target_batch, sum_of_mnist_rand_num_target_batch) = \\\n",
        "            batch_in2\n",
        "        data_in1, target_in1 = \\\n",
        "            mnist_image_batch.to(device), mnist_target_batch.to(device)\n",
        "        data_in2, target_in2 = \\\n",
        "            rand_num_in_batch.to(device), \\\n",
        "            sum_of_mnist_rand_num_target_batch.to(device)\n",
        "        '''above moves the mini-batch data and targets to the specified \n",
        "        device (e.g. CPU or GPU). '''\n",
        "        optimizer_in1.zero_grad()\n",
        "        optimizer_in2.zero_grad()\n",
        "        '''In PyTorch, for every mini-batch during the training phase, \n",
        "        we typically want to explicitly set the gradients to zero before \n",
        "        starting to do backpropagation (i.e., updating the Weights) because \n",
        "        PyTorch accumulates the gradients on subsequent backward \n",
        "        passes.i.e.the default action is set to accumulate (i.e. sum) the \n",
        "        gradients on every loss.backward() call. Because of this, when one \n",
        "        starts training loop, should zero out the gradients so that the \n",
        "        parameter update correctly. Otherwise, the gradient would be a \n",
        "        combination of the old gradient, which has already been used to \n",
        "        update model parameters, and the newly-computed gradient. '''\n",
        "        output_in1, output_in2 = model(data_in1, data_in2)\n",
        "        '''above passes the mini-batch data through the model to make \n",
        "        predictions. '''\n",
        "        loss_in1 = F.cross_entropy(output_in1, target_in1)\n",
        "        train_losses_in1.append(loss_in1.item())\n",
        "        loss_in2 = F.cross_entropy(output_in2, target_in2)\n",
        "        train_losses_in2.append(loss_in2.item())\n",
        "\n",
        "        loss_in1.backward()\n",
        "        loss_in2.backward()\n",
        "        '''above calculates the gradients of the loss with respect to the \n",
        "        model's parameters. This is done using backpropagation. '''\n",
        "        optimizer_in1.step()\n",
        "        optimizer_in2.step()\n",
        "        '''above updates the model's parameters using the gradients and the \n",
        "        optimizer's update rule. '''\n",
        "        pred_in1 = output_in1.argmax(dim=1,\n",
        "                                     keepdim=True)  # get the index of the max\n",
        "        # log-probability\n",
        "        pred_in2 = output_in2.argmax(dim=1,\n",
        "                                     keepdim=True)  # get the index of the max\n",
        "        # log-probability\n",
        "        correct_in1 += pred_in1.eq(target_in1.view_as(pred_in1)).sum().item()\n",
        "        correct_in2 += get_correct_pred_count(pred_in2, target_in2)\n",
        "        processed_in1 += len(data_in1)\n",
        "        processed_in2 += len(data_in2)\n",
        "        '''updates the progress bar with the current loss and batch index. \n",
        "        This allows the user to see the progress of the training loop and the \n",
        "        current loss. '''\n",
        "        pbar.set_description(desc=f'loss_in1={loss_in1.item()}  '\n",
        "                                  f'loss_in2={loss_in2.item()} '\n",
        "                                  f'Accuracy_in1= '\n",
        "                                  f'{correct_in1}/{len(train_loader.dataset)} '\n",
        "                                  f'({100 * correct_in1 / processed_in1:0.2f})%'\n",
        "                                  f'Accuracy_in2= '\n",
        "                                  f'{correct_in2}/{len(train_loader.dataset)} '\n",
        "                                  f'({100 * correct_in2 / processed_in2:0.2f})%'\n",
        "                                  f'batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test_model(model, device, test_loader):\n",
        "    model.eval()\n",
        "    '''model.eval() sets the model to test mode. This is typically done \n",
        "    because some models have different behaviors in training and evaluation \n",
        "    modes. '''\n",
        "    test_loss_in1 = 0\n",
        "    test_loss_in2 = 0\n",
        "    correct_in1 = 0\n",
        "    correct_in2 = 0\n",
        "    with torch.no_grad():\n",
        "        '''When testing a model, don't want to compute gradients since we are \n",
        "        not training the model. Disabling gradients can save memory and can \n",
        "        make the computations faster. This is why it is common to see a \n",
        "        torch.no_grad() context manager used inside a test function. It \n",
        "        prevents the computations inside the block from tracking gradients, \n",
        "        which can save memory and improve performance. '''\n",
        "        for (batch_in1, batch_in2) in test_loader:\n",
        "            (mnist_image_batch, rand_num_in_batch) = batch_in1\n",
        "            (mnist_target_batch, sum_of_mnist_rand_num_target_batch) = \\\n",
        "                batch_in2\n",
        "            data_in1, target_in1 = \\\n",
        "                mnist_image_batch.to(device), mnist_target_batch.to(device)\n",
        "            data_in2, target_in2 = \\\n",
        "                rand_num_in_batch.to(device), \\\n",
        "                sum_of_mnist_rand_num_target_batch.to(device)\n",
        "            output_in1, output_in2 = model(data_in1, data_in2)\n",
        "            test_loss_in1 += \\\n",
        "                F.cross_entropy(output_in1, target_in1,\n",
        "                                reduction='sum').item()  # sum\n",
        "            test_loss_in2 += \\\n",
        "                F.cross_entropy(output_in2, target_in2,\n",
        "                                reduction='sum').item()  # sum\n",
        "            # up batch loss\n",
        "            pred_in1 = output_in1.argmax(dim=1, keepdim=True)  # get the\n",
        "            # index of the max log-probability\n",
        "            pred_in2 = output_in1.argmax(dim=1, keepdim=True)  # get the\n",
        "            # index of the max log-probability\n",
        "            correct_in1 += pred_in1.eq(\n",
        "                target_in1.view_as(pred_in1)).sum().item()\n",
        "            correct_in2 += get_correct_pred_count(pred_in2, target_in2)\n",
        "\n",
        "            '''Here, pred and target are tensors that represent the model's \n",
        "            predictions and the true targets, respectively. The .eq() method \n",
        "            is used to compare the two tensors element-wise, and returns a \n",
        "            tensor of the same shape with binary values (0 or 1) indicating \n",
        "            whether the corresponding elements in pred and target are equal. \n",
        "            The .sum() method is used to sum all the elements in the tensor, \n",
        "            and the .item() method is used to convert the resulting scalar \n",
        "            tensor to a Python scalar. So the overall effect of this code is \n",
        "            to compute the number of correct predictions made by the model \n",
        "            and add it to the correct variable. '''\n",
        "\n",
        "    '''below test_loss is a variable that represents the average loss across \n",
        "    all the test examples, and test_loader.dataset is a dataset object that \n",
        "    contains all the test examples. The len() function is used to compute the \n",
        "    number of examples in the dataset, and this value is used to divide the \n",
        "    test_loss by the number of examples. The result is the average loss per \n",
        "    example, which is a more useful metric for evaluating the model's \n",
        "    performance. '''\n",
        "    test_loss_in1 /= len(test_loader.dataset)\n",
        "    test_loss_in2 /= len(test_loader.dataset)\n",
        "\n",
        "    print(\n",
        "        '\\nTest set: Average loss_in1: {:.4f}, '\n",
        "        'Accuracy_in1: {}/{} ({:.0f}%)\\n'.format(test_loss_in1,\n",
        "                                                 correct_in1,\n",
        "                                                 len(test_loader.dataset),\n",
        "                                                 100. * correct_in1 /\n",
        "                                                 len(test_loader.dataset)))\n",
        "\n",
        "    print(\n",
        "        '\\nTest set: Average loss_in2: {:.4f}, '\n",
        "        'Accuracy_in2: {}/{} ({:.0f}%)\\n'.format(test_loss_in2,\n",
        "                                                 correct_in2,\n",
        "                                                 len(test_loader.dataset),\n",
        "                                                 100. * correct_in2 /\n",
        "                                                 len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fGXGEnQve07-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9b4777cd-a11a-4236-95b7-568a0b92654d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available? True\n",
            "device:  cuda\n",
            "\n",
            "\t***Display some of the data thus generated:\n",
            "\n",
            "mnist_image.shape:  torch.Size([128, 1, 28, 28])\n",
            "rand_num_in.shape:  torch.Size([128, 10])\n",
            "mnist_target.shape:  torch.Size([128])\n",
            "sum_of_mnist_rand_num_target.shape:  torch.Size([128, 19])\n",
            "rand_num_in[44]=  0\n",
            "mnist_target[44]=  0\n",
            "sum_of_mnist_rand_num_target[44]=  6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mnist_image.shape:  torch.Size([128, 1, 28, 28])\n",
            "rand_num_in.shape:  torch.Size([128, 10])\n",
            "mnist_target.shape:  torch.Size([128])\n",
            "sum_of_mnist_rand_num_target.shape:  torch.Size([128, 19])\n",
            "rand_num_in[47]=  2\n",
            "mnist_target[47]=  0\n",
            "sum_of_mnist_rand_num_target[47]=  6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mnist_image.shape:  torch.Size([128, 1, 28, 28])\n",
            "rand_num_in.shape:  torch.Size([128, 10])\n",
            "mnist_target.shape:  torch.Size([128])\n",
            "sum_of_mnist_rand_num_target.shape:  torch.Size([128, 19])\n",
            "rand_num_in[117]=  7\n",
            "mnist_target[117]=  0\n",
            "sum_of_mnist_rand_num_target[117]=  16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mnist_image.shape:  torch.Size([128, 1, 28, 28])\n",
            "rand_num_in.shape:  torch.Size([128, 10])\n",
            "mnist_target.shape:  torch.Size([128])\n",
            "sum_of_mnist_rand_num_target.shape:  torch.Size([128, 19])\n",
            "rand_num_in[64]=  2\n",
            "mnist_target[64]=  0\n",
            "sum_of_mnist_rand_num_target[64]=  5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mnist_image.shape:  torch.Size([128, 1, 28, 28])\n",
            "rand_num_in.shape:  torch.Size([128, 10])\n",
            "mnist_target.shape:  torch.Size([128])\n",
            "sum_of_mnist_rand_num_target.shape:  torch.Size([128, 19])\n",
            "rand_num_in[67]=  7\n",
            "mnist_target[67]=  0\n",
            "sum_of_mnist_rand_num_target[67]=  11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "SEED = 1\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", cuda)\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "print(\"device: \", device)\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "# Create a consolidated Dataset:\n",
        "train_data, test_data, train_target, test_target = source_data()\n",
        "train_data_set = MNIST_RAND_IN_Dataset(train_data, test_data, train_target,\n",
        "                                       test_target,\n",
        "                                       train=True, test=False,\n",
        "                                       # Required transforms for In1(for\n",
        "                                       # part 1 of the NN)\n",
        "                                       transform_in1=transforms.Compose(\n",
        "                                           [  # for input 1 mnist image only\n",
        "                                               transforms.ToTensor(),\n",
        "                                               transforms.Normalize(\n",
        "                                                   (0.1307,),\n",
        "                                                   (0.3081,))\n",
        "                                           ])\n",
        "                                       # Not Required transforms for In2(for\n",
        "                                       # part 2 of the NN)\n",
        "                                       )\n",
        "test_data_set = MNIST_RAND_IN_Dataset(train_data, test_data, train_target,\n",
        "                                      test_target,\n",
        "                                      train=False, test=True,\n",
        "                                      # Required transforms for In1(for\n",
        "                                      # part 1 of the NN)\n",
        "                                      transform_in1=transforms.Compose(\n",
        "                                          [  # for input 1 mnist image only\n",
        "                                              transforms.ToTensor(),\n",
        "                                              transforms.Normalize(\n",
        "                                                  (0.1307,),\n",
        "                                                  (0.3081,))\n",
        "                                          ])\n",
        "                                      # Not Required transforms for In2(for\n",
        "                                      # part 2 of the NN)\n",
        "                                      )\n",
        "train_dataloader_args = dict(shuffle=True, batch_size=batch_size,\n",
        "                             num_workers=2,\n",
        "                             pin_memory=True) if cuda else \\\n",
        "    dict(shuffle=False, batch_size=batch_size)\n",
        "test_dataloader_args = dict(shuffle=True, batch_size=batch_size,\n",
        "                            num_workers=2, pin_memory=True) if cuda else \\\n",
        "    dict(shuffle=True, batch_size=batch_size)\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train_data_set,\n",
        "                                           **train_dataloader_args)\n",
        "# test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test_data_set,\n",
        "                                          **test_dataloader_args)\n",
        "print(\"\\n\\t***Display some of the data thus generated:\\n\")\n",
        "display_few_batch_samples(train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Finally train and test the neural network (there were many in-between debug steps, like starting out with single sampl, going on to batch sample & testing backpropagation and gradient updates & loss and accuracy checks, that were performed at my own end, and are not displayed here)Here The final test and train function are used to display the final set of results.At this point, the progress bars and the messages show the improvements in the results for the MNSIT predictions but a dismal 1% for the sum_out prediction (which was kind of expected as the input and output spaces are from a random distribution and hence network is not supposed to learn for the 2nd part)"
      ],
      "metadata": {
        "id": "iDPmXR7Lsj0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net(1).to(device)\n",
        "'''above creates an instance of a PyTorch neural network model, and then \n",
        "moves the model to the specified device (CPU or GPU). In this case, \n",
        "Net() creates an instance of a neural network class called Net, and the to(\n",
        "device) method moves the model to the device specified by the device \n",
        "variable. This line of code is typically used in conjunction with the device \n",
        "variable being set to a torch.device object that represents the device (CPU \n",
        "or GPU) on which the model should be allocated '''\n",
        "\n",
        "'''below optim.SGD() function is used to create the optimizer objectss, and it \n",
        "takes several arguments. The first argument is the model.parameters(), \n",
        "which tells the optimizer which parameters of the model to update during \n",
        "training. The lr argument specifies the learning rate, which determines the \n",
        "size of the step that the optimizer takes in the direction of the gradient. \n",
        "The momentum argument specifies the momentum, which is a technique that can \n",
        "improve the performance of the optimizer and can help the model converge \n",
        "faster. In this case, the optimizer is configured to use a learning rate of \n",
        "0.01 and a momentum of 0.9. '''\n",
        "optimizer_in1 = optim.SGD(params=[param for name, param in\n",
        "                                  model.named_parameters() if\n",
        "                                  'conv' in name], lr=0.01, momentum=0.9)\n",
        "optimizer_in2 = optim.SGD(params=[param for name, param in\n",
        "                                  model.named_parameters() if\n",
        "                                  'fc' in name], lr=0.01, momentum=0.9)\n",
        "\n",
        "'''This following code trains a model for one epoch and then tests the model \n",
        "on the test set.  '''\n",
        "for epoch in range(0, 10):\n",
        "    print(\"EPOCH:\", epoch + 1)\n",
        "    train_model(model, device, train_loader, optimizer_in1, optimizer_in2)\n",
        "    test_model(model, device, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "za8OUCfhqsqB",
        "outputId": "c220ba10-0e57-453c-bcb9-c2a97f8eab28"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss_in1=0.16461284458637238  loss_in2=2.5868406295776367 Accuracy_in1= 52431/60000 (87.39)%Accuracy_in2= 593/60000 (0.99)%batch_id=468: 100%|| 469/469 [00:18<00:00, 24.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss_in1: 0.0612, Accuracy_in1: 9798/10000 (98%)\n",
            "\n",
            "\n",
            "Test set: Average loss_in2: 2.5501, Accuracy_in2: 104/10000 (1%)\n",
            "\n",
            "EPOCH: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss_in1=0.02296634577214718  loss_in2=2.411694049835205 Accuracy_in1= 58965/60000 (98.28)%Accuracy_in2= 593/60000 (0.99)%batch_id=468: 100%|| 469/469 [00:17<00:00, 27.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss_in1: 0.0378, Accuracy_in1: 9871/10000 (99%)\n",
            "\n",
            "\n",
            "Test set: Average loss_in2: 2.3789, Accuracy_in2: 104/10000 (1%)\n",
            "\n",
            "EPOCH: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss_in1=0.06819497793912888  loss_in2=2.325798511505127 Accuracy_in1= 59313/60000 (98.86)%Accuracy_in2= 593/60000 (0.99)%batch_id=468: 100%|| 469/469 [00:19<00:00, 23.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss_in1: 0.0342, Accuracy_in1: 9898/10000 (99%)\n",
            "\n",
            "\n",
            "Test set: Average loss_in2: 2.3362, Accuracy_in2: 104/10000 (1%)\n",
            "\n",
            "EPOCH: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss_in1=0.038997381925582886  loss_in2=2.325326919555664 Accuracy_in1= 59533/60000 (99.22)%Accuracy_in2= 593/60000 (0.99)%batch_id=468: 100%|| 469/469 [00:20<00:00, 22.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss_in1: 0.0265, Accuracy_in1: 9909/10000 (99%)\n",
            "\n",
            "\n",
            "Test set: Average loss_in2: 2.3230, Accuracy_in2: 104/10000 (1%)\n",
            "\n",
            "EPOCH: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss_in1=0.023021982982754707  loss_in2=2.311291456222534 Accuracy_in1= 59664/60000 (99.44)%Accuracy_in2= 593/60000 (0.99)%batch_id=468: 100%|| 469/469 [00:19<00:00, 24.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss_in1: 0.0247, Accuracy_in1: 9917/10000 (99%)\n",
            "\n",
            "\n",
            "Test set: Average loss_in2: 2.3163, Accuracy_in2: 104/10000 (1%)\n",
            "\n",
            "EPOCH: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss_in1=0.004348824732005596  loss_in2=2.3146703243255615 Accuracy_in1= 59728/60000 (99.55)%Accuracy_in2= 593/60000 (0.99)%batch_id=468: 100%|| 469/469 [00:18<00:00, 25.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss_in1: 0.0333, Accuracy_in1: 9893/10000 (99%)\n",
            "\n",
            "\n",
            "Test set: Average loss_in2: 2.3130, Accuracy_in2: 104/10000 (1%)\n",
            "\n",
            "EPOCH: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss_in1=0.0016020615585148335  loss_in2=2.3381497859954834 Accuracy_in1= 59749/60000 (99.58)%Accuracy_in2= 593/60000 (0.99)%batch_id=468: 100%|| 469/469 [00:19<00:00, 24.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss_in1: 0.0253, Accuracy_in1: 9923/10000 (99%)\n",
            "\n",
            "\n",
            "Test set: Average loss_in2: 2.3081, Accuracy_in2: 104/10000 (1%)\n",
            "\n",
            "EPOCH: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss_in1=0.017069902271032333  loss_in2=2.319537401199341 Accuracy_in1= 59847/60000 (99.75)%Accuracy_in2= 593/60000 (0.99)%batch_id=468: 100%|| 469/469 [00:19<00:00, 23.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss_in1: 0.0270, Accuracy_in1: 9917/10000 (99%)\n",
            "\n",
            "\n",
            "Test set: Average loss_in2: 2.3129, Accuracy_in2: 104/10000 (1%)\n",
            "\n",
            "EPOCH: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss_in1=0.0015650457935407758  loss_in2=2.324920654296875 Accuracy_in1= 59848/60000 (99.75)%Accuracy_in2= 593/60000 (0.99)%batch_id=468: 100%|| 469/469 [00:19<00:00, 24.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss_in1: 0.0261, Accuracy_in1: 9926/10000 (99%)\n",
            "\n",
            "\n",
            "Test set: Average loss_in2: 2.3122, Accuracy_in2: 104/10000 (1%)\n",
            "\n",
            "EPOCH: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss_in1=0.0033914356026798487  loss_in2=2.316932439804077 Accuracy_in1= 59881/60000 (99.80)%Accuracy_in2= 593/60000 (0.99)%batch_id=468: 100%|| 469/469 [00:19<00:00, 23.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss_in1: 0.0282, Accuracy_in1: 9910/10000 (99%)\n",
            "\n",
            "\n",
            "Test set: Average loss_in2: 2.3111, Accuracy_in2: 104/10000 (1%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xxBiAv4Brven"
      },
      "execution_count": 10,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}